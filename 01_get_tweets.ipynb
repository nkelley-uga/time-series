{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECON 6760 Final\n",
    "\n",
    "---\n",
    "\n",
    "# Tweet Scraping\n",
    "\n",
    "Following is the platform we used to retrieve tweets from \"@Wendys,\" the eponymous corporate twitter account.\n",
    "\n",
    "Our goal with this project is to investigate a VAR model that predicts the stock price of Wendys (NASDQ: WEN) by integrating data from Twitter. The fields being retrieved are: tweet datetime, tweet text, number of time the tweet was favorited, and number of times the tweet was retweeted. The latter fields can be thought of as metrics that lead to higher exposure; since retweets lead to more reads, and favorites lead to the tweet being \"bumped-up\" in the twitter feeds of relevant readers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # holding tweets in a dataframe\n",
    "import GetOldTweets3 as got  # API to scrape tweets\n",
    "import time  # time.sleep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_df(target, start, stop):\n",
    "    '''\n",
    "    Function to scrape tweets from the GetOldTweets3 API into a dataframe.\n",
    "    \n",
    "    Refer to [https://pypi.org/project/GetOldTweets3/] for additional info and tweet fields.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    user: the username of target tweeter - could be changed easily to text scrape\n",
    "    start: inclusive date to start scraping\n",
    "    stop: exclusive date to stop scraping\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>tweet_to_df('@Wendys', '2018-01-01', '2018-02-01')\n",
    "    returns a dataframe of size (3354, 4) of tweets by '@Wendys' during Jan of 2018\n",
    "    '''\n",
    "    tweetCriteria = got.manager.TweetCriteria()\\\n",
    "                                .setQuerySearch(target)\\\n",
    "                                .setSince(start)\\\n",
    "                                .setUntil(stop)\n",
    "    \n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    text_tweets = [[tweet.date, \n",
    "                    tweet.username,\n",
    "                    tweet.text,\n",
    "                    tweet.favorites, \n",
    "                    tweet.retweets]\n",
    "                   for tweet in tweets]\n",
    "    \n",
    "    return pd.DataFrame(text_tweets,\n",
    "                        columns=['datetime', \n",
    "                                 'username',\n",
    "                                 'text',\n",
    "                                 'favorites', \n",
    "                                 'retweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.92 s, sys: 261 ms, total: 6.18 s\n",
      "Wall time: 38.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(867, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# scrape boundaries - NOTE: limit of 10k / 15 mins\n",
    "start = '2018-01-01'\n",
    "stop = '2018-01-02'\n",
    "\n",
    "# scrape-and-store\n",
    "raw_data = tweet_to_df('@Wendys', start, stop)    \n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01 23:59:56+00:00</td>\n",
       "      <td>kappi464</td>\n",
       "      <td>@Wendys Only 2 chains raps are more fresh then...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 23:59:34+00:00</td>\n",
       "      <td>MyRealityIsMe</td>\n",
       "      <td>When I go to @Wendys this week in the DMV area...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-01 23:57:56+00:00</td>\n",
       "      <td>alekzandr904</td>\n",
       "      <td>my brothers titanium legs are as cold as @McDo...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-01 23:55:13+00:00</td>\n",
       "      <td>HouseOfDamaged</td>\n",
       "      <td>check out our clothing line bringing awareness...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-01 23:52:58+00:00</td>\n",
       "      <td>SoundDiel</td>\n",
       "      <td>Never going to another place for nuggets. Got ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime        username  \\\n",
       "0 2018-01-01 23:59:56+00:00        kappi464   \n",
       "1 2018-01-01 23:59:34+00:00   MyRealityIsMe   \n",
       "2 2018-01-01 23:57:56+00:00    alekzandr904   \n",
       "3 2018-01-01 23:55:13+00:00  HouseOfDamaged   \n",
       "4 2018-01-01 23:52:58+00:00       SoundDiel   \n",
       "\n",
       "                                                text  favorites  retweets  \n",
       "0  @Wendys Only 2 chains raps are more fresh then...          0         0  \n",
       "1  When I go to @Wendys this week in the DMV area...          0         0  \n",
       "2  my brothers titanium legs are as cold as @McDo...          2         2  \n",
       "3  check out our clothing line bringing awareness...          1         0  \n",
       "4  Never going to another place for nuggets. Got ...          2         1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()  # tweets are ordered with most recent on top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Iterating Scrape\n",
    "\n",
    "As of this writing, Twitter imposes a limit on API hits. That limit is 10k requests per 15 minutes.\n",
    "\n",
    "How you workaround that is totally up to you, here are a couple of ways that I found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually adjust the dates to different months and wait\n",
    "start = '2018-02-01'\n",
    "stop = '2018-03-01'\n",
    "\n",
    "# after each new scrape append the new data to the old\n",
    "more_data = tweet_to_df('@Wendys', start, stop)\n",
    "raw_data = raw_data.append(more_data, ignore_index=True)\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "sdate = date(2018, 1, 4)   # start date\n",
    "edate = date(2018, 12, 31)   # end date\n",
    "\n",
    "delta = edate - sdate       # as timedelta\n",
    "dates = []\n",
    "for i in range(delta.days + 1):\n",
    "    day = sdate + timedelta(days=i)\n",
    "    dates.append(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working... 25741 rows now\n",
      "working... 30338 rows now\n",
      "working... 33523 rows now\n",
      "working... 35776 rows now\n",
      "working... 37676 rows now\n",
      "working... 39453 rows now\n",
      "working... 41401 rows now\n",
      "working... 43065 rows now\n",
      "working... 44608 rows now\n",
      "working... 45783 rows now\n",
      "working... 47060 rows now\n",
      "working... 48685 rows now\n",
      "working... 50398 rows now\n",
      "working... 51874 rows now\n",
      "working... 53217 rows now\n",
      "working... 54744 rows now\n",
      "working... 55853 rows now\n",
      "working... 56916 rows now\n",
      "working... 58123 rows now\n",
      "working... 59323 rows now\n",
      "working... 70028 rows now\n",
      "working... 74149 rows now\n",
      "working... 76782 rows now\n",
      "working... 78758 rows now\n",
      "working... 80057 rows now\n",
      "working... 81110 rows now\n",
      "working... 82275 rows now\n",
      "working... 84985 rows now\n",
      "working... 87025 rows now\n",
      "working... 88868 rows now\n",
      "working... 90555 rows now\n",
      "working... 93180 rows now\n",
      "working... 100758 rows now\n",
      "working... 103177 rows now\n",
      "working... 105476 rows now\n",
      "working... 107550 rows now\n",
      "working... 109603 rows now\n",
      "working... 112249 rows now\n",
      "working... 116466 rows now\n",
      "working... 124370 rows now\n",
      "working... 133548 rows now\n",
      "working... 139369 rows now\n",
      "working... 143277 rows now\n",
      "working... 145822 rows now\n",
      "working... 147876 rows now\n",
      "working... 150119 rows now\n",
      "working... 153063 rows now\n",
      "working... 156381 rows now\n",
      "working... 159354 rows now\n",
      "working... 161990 rows now\n",
      "working... 164440 rows now\n",
      "working... 166672 rows now\n",
      "working... 169119 rows now\n",
      "working... 172551 rows now\n",
      "working... 177211 rows now\n",
      "An error occured during an HTTP request: HTTP Error 503: Service Temporarily Unavailable\n",
      "Try to open in browser: https://twitter.com/search?q=%40Wendys%20since%3A2018-02-28%20until%3A2018-03-01&src=typd\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# baked-in waiting\n",
    "for d in dates:\n",
    "    start = str(d)\n",
    "    stop = str(d + timedelta(days=1))\n",
    "    # and scrape\n",
    "    more_data = tweet_to_df('@Wendys', start, stop)\n",
    "    raw_data = raw_data.append(more_data, ignore_index=True)\n",
    "    print(f'working... {raw_data.shape[0]} rows now')  # for sanity\n",
    "    time.sleep(60*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>177206</td>\n",
       "      <td>2018-02-27 23:59:22+00:00</td>\n",
       "      <td>GloBowler</td>\n",
       "      <td>I just voted for Devonte' Graham for the @Wend...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177207</td>\n",
       "      <td>2018-02-27 23:59:24+00:00</td>\n",
       "      <td>itsyaboynate14</td>\n",
       "      <td>@Wendys can you deliver to mi casa?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177208</td>\n",
       "      <td>2018-02-27 23:59:36+00:00</td>\n",
       "      <td>JmfSavage</td>\n",
       "      <td>I just had the best smoky mushroom burger, mad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177209</td>\n",
       "      <td>2018-02-27 23:59:49+00:00</td>\n",
       "      <td>storybrooke28</td>\n",
       "      <td>I just voted for Marvin Bagley III for the @We...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177210</td>\n",
       "      <td>2018-02-27 23:59:53+00:00</td>\n",
       "      <td>Coachbird24</td>\n",
       "      <td>I just voted for Devonte' Graham for the @Wend...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        datetime        username  \\\n",
       "177206 2018-02-27 23:59:22+00:00       GloBowler   \n",
       "177207 2018-02-27 23:59:24+00:00  itsyaboynate14   \n",
       "177208 2018-02-27 23:59:36+00:00       JmfSavage   \n",
       "177209 2018-02-27 23:59:49+00:00   storybrooke28   \n",
       "177210 2018-02-27 23:59:53+00:00     Coachbird24   \n",
       "\n",
       "                                                     text  favorites  retweets  \n",
       "177206  I just voted for Devonte' Graham for the @Wend...          0         0  \n",
       "177207                @Wendys can you deliver to mi casa?          0         0  \n",
       "177208  I just had the best smoky mushroom burger, mad...          0         0  \n",
       "177209  I just voted for Marvin Bagley III for the @We...          0         0  \n",
       "177210  I just voted for Devonte' Graham for the @Wend...          1         0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = raw_data.drop_duplicates().sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "raw_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any duplicates and save to csv\n",
    "\n",
    "raw_data.drop_duplicates().to_csv('all_mentions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
